{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первом исследовании (select features.ipynb) на 100 пользователях для разных методов были найдены признаки, которые дают максимальную точность классификации. Лучшие результаты были получены с помощью методов:\n",
    "\n",
    "метод                | средняя точность на контрольной | точность на тестовой\n",
    "---------------------|---------------------------------|---------------------\n",
    "KNeighborsClassifier | 0.93                            | 0.97\n",
    "LogisticRegression   | 0.99                            | 1.0\n",
    "SVC                  | 0.99                            | 0.99\n",
    "\n",
    "Остальные методы проявили себя значительно слабее. Зная, какие признаки были выбраны для каждого их приведёных методов, можно выбрать наиболее часто встречающиеся признаки по каждому из методов и по всем методам и оценить точность классификации, но уже на полной выборке из 1220 пользователей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_feat = [(3, 3), (4, 3), (6, 3), (11, 3), (2, 3), (1, 3), (13, 3), (10, 3), (5, 3), (12, 3), (7, 3), (28, 3), (9, 3), (0, 2), (27, 2), (19, 2), (14, 2), (8, 2), (15, 2), (29, 1), (18, 1), (23, 1), (33, 1), (36, 1), (37, 1), (41, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (34, 1), (20, 1)]\n",
    "log_feat = [(27, 3), (7, 3), (4, 3), (2, 3), (3, 3), (0, 3), (8, 3), (9, 3), (6, 3), (13, 3), (12, 3), (1, 3), (11, 2), (10, 2), (5, 2), (28, 2), (36, 2), (15, 2), (19, 1), (32, 1), (25, 1), (21, 1), (20, 1), (35, 1), (14, 1)]\n",
    "svc_feat = [(2, 3), (5, 3), (9, 3), (11, 3), (27, 3), (8, 3), (10, 3), (6, 3), (7, 3), (1, 3), (3, 3), (34, 3), (4, 3), (13, 3), (28, 2), (0, 2), (12, 2), (15, 2), (19, 1), (29, 1), (41, 1), (37, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (32, 1), (36, 1), (20, 1), (25, 1), (18, 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_set = np.load('train_set.npy')\n",
    "test_set = np.load('test_set.npy')\n",
    "\n",
    "X_train = np.nan_to_num(train_set[:, :-1])\n",
    "X_test = np.nan_to_num(test_set[:, :-1])\n",
    "\n",
    "y_train = train_set[:, -1].astype(int)\n",
    "y_test = test_set[:, -1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим каждую из моделей на признаках, которые встречаются 3 раза и 2 раза, и оценим точность на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(feat):\n",
    "    count = 1\n",
    "    \n",
    "    while len(sorted([item[0] for item in feat if item[1] >= count])) > 0:\n",
    "        yield sorted([item[0] for item in feat if item[1] >= count]), count\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8155737704918032 при count 1\n",
      "0.8336065573770491 при count 2\n",
      "0.8245901639344262 при count 3\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "for indexes, count in features(knn_feat):\n",
    "    model.fit(X_train[:, indexes], y_train)\n",
    "    print(model.score(X_test[:, indexes], y_test), 'при count', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8967213114754098 при count 1\n",
      "0.8844262295081967 при count 2\n",
      "0.7959016393442623 при count 3\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1_000)\n",
    "\n",
    "for indexes, count in features(log_feat):\n",
    "    model.fit(X_train[:, indexes], y_train)\n",
    "    print(model.score(X_test[:, indexes], y_test), 'при count', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8704918032786885 при count 1\n",
      "0.8934426229508197 при count 2\n",
      "0.8704918032786885 при count 3\n"
     ]
    }
   ],
   "source": [
    "model = SVC(gamma='auto')\n",
    "\n",
    "for indexes, count in features(svc_feat):\n",
    "    model.fit(X_train[:, indexes], y_train)\n",
    "    print(model.score(X_test[:, indexes], y_test), 'при count', count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучший результат показывают методы логистическая регрессия на признаках, которые встречаются 1 раз и чаще, и метод опорных векторов на признаках, которые встречаются 2 раза и чаще."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим на совокупности признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "all_feat = Counter()\n",
    "\n",
    "for item in knn_feat:\n",
    "    all_feat[item[0]] += item[1]\n",
    "\n",
    "for item in log_feat:\n",
    "    all_feat[item[0]] += item[1]\n",
    "\n",
    "for item in svc_feat:\n",
    "    all_feat[item[0]] += item[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7918032786885246 при count 1\n",
      "0.8172131147540984 при count 2\n",
      "0.8237704918032787 при count 3\n",
      "0.830327868852459 при count 4\n",
      "0.8336065573770491 при count 5\n",
      "0.8336065573770491 при count 6\n",
      "0.8418032786885246 при count 7\n",
      "0.830327868852459 при count 8\n",
      "0.6475409836065574 при count 9\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "for indexes, count in features(all_feat.most_common()):\n",
    "    model.fit(X_train[:, indexes], y_train)\n",
    "    print(model.score(X_test[:, indexes], y_test), 'при count', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9057377049180327 при count 1\n",
      "0.9016393442622951 при count 2\n",
      "0.8918032786885246 при count 3\n",
      "0.8975409836065574 при count 4\n",
      "0.8803278688524591 при count 5\n",
      "0.8803278688524591 при count 6\n",
      "0.8885245901639345 при count 7\n",
      "0.8721311475409836 при count 8\n",
      "0.5688524590163935 при count 9\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1_000)\n",
    "\n",
    "for indexes, count in features(all_feat.most_common()):\n",
    "    model.fit(X_train[:, indexes], y_train)\n",
    "    print(model.score(X_test[:, indexes], y_test), 'при count', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8786885245901639 при count 1\n",
      "0.8704918032786885 при count 2\n",
      "0.8729508196721312 при count 3\n",
      "0.8762295081967213 при count 4\n",
      "0.8811475409836066 при count 5\n",
      "0.8811475409836066 при count 6\n",
      "0.8778688524590164 при count 7\n",
      "0.8762295081967213 при count 8\n",
      "0.7139344262295082 при count 9\n"
     ]
    }
   ],
   "source": [
    "model = SVC(gamma='auto')\n",
    "\n",
    "for indexes, count in features(all_feat.most_common()):\n",
    "    model.fit(X_train[:, indexes], y_train)\n",
    "    print(model.score(X_test[:, indexes], y_test), 'при count', count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На совокупности признаков лучшие результаты показали модели LogisticRegression и SVC. Логистическая регрессия показала точность 90% на тестовой выборке, но при этом использовались все признаки, что не очень хорошо, т.к. такая модель, вероятно, обладает меньшей обобщающей способностью. В то же время на признаках, которые встречаются 4 или 5 раз обе модели показали примерно равный результат - 88 - 89%. Вот соответствующие признаки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 19, 27, 28, 34, 36]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 27, 28]\n"
     ]
    }
   ],
   "source": [
    "for indexes, count in features(all_feat.most_common()):\n",
    "    if count == 4 or count == 5:\n",
    "        print(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее, ипользуя только эти признаки, стоит выполнить настройку параметров моделей для максимального эффекта на кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stas\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'C': [0.01, 0.1, 1, 10], 'solver': ['newton-cg', 'lbfgs', 'sag', 'saga']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 27, 28]\n",
    "\n",
    "parameters = {\n",
    "    'C'      : [0.01, 0.1, 1, 10],\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'sag', 'saga']}\n",
    "\n",
    "estimator = GridSearchCV(LogisticRegression(), parameters, cv=3, n_jobs=-1)\n",
    "estimator.fit(X_train[:, indexes], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='newton-cg',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "best_score_ 0.8314207650273224\n",
      "Точность на тестовой выборке 0.8663934426229508\n"
     ]
    }
   ],
   "source": [
    "print(estimator.best_estimator_)\n",
    "print('best_score_', estimator.best_score_)\n",
    "print('Точность на тестовой выборке', estimator.best_estimator_.score(X_test[:, indexes], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'C': [0.01, 0.1, 1, 10], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'degree': [2, 3, 4, 5], 'gamma': ['auto', 'scale']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'C'      : [0.01, 0.1, 1, 10],\n",
    "    'kernel' : ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'degree' : [2, 3, 4, 5],\n",
    "    'gamma'  : ['auto', 'scale']}\n",
    "\n",
    "estimator = GridSearchCV(SVC(), parameters, cv=3, n_jobs=-1)\n",
    "estimator.fit(X_train[:, indexes], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=2, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "best_score_ 0.8696721311475409\n",
      "Точность на тестовой выборке 0.9040983606557377\n"
     ]
    }
   ],
   "source": [
    "print(estimator.best_estimator_)\n",
    "print('best_score_', estimator.best_score_)\n",
    "print('Точность на тестовой выборке', estimator.best_estimator_.score(X_test[:, indexes], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
