{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем снижение размерности PCA на пространстве всех признаков. Попробуем использовать различные модели. Выберем из них наилучшую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = np.load('train_set.npy')\n",
    "test_set = np.load('test_set.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set[:, :-1]\n",
    "y_train = train_set[:, -1].astype(int)\n",
    "\n",
    "X_test = test_set[:, :-1]\n",
    "y_test = test_set[:, -1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.nan_to_num(X_train)\n",
    "X_test = np.nan_to_num(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим все модели для подпространств признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {'mfcc': 26, 'lpc': 10, 'formants': 13}\n",
    "\n",
    "mfcc_slice = slice(0, counts['mfcc'])\n",
    "lpc_slice = slice(counts['mfcc'], counts['mfcc'] + counts['lpc'])\n",
    "formants_slice = slice(counts['mfcc'] + counts['lpc'], counts['mfcc'] + counts['lpc'] + counts['formants'])\n",
    "whole_slice = slice(0, counts['mfcc'] + counts['lpc'] + counts['formants'])\n",
    "\n",
    "slices = {'mfcc': mfcc_slice, 'lpc': lpc_slice, 'formants': formants_slice, 'whole': whole_slice}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [KNeighborsClassifier(n_neighbors=3),\n",
    "          LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000),\n",
    "          GaussianNB(),\n",
    "          SVC(gamma='auto'),\n",
    "          MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=1000),\n",
    "          DecisionTreeClassifier(min_samples_leaf=2),\n",
    "          RandomForestClassifier(min_samples_leaf=2, n_estimators=20)\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исследование подмножества признаков mfcc\n",
      "KNeighborsClassifier\n",
      "Оптимальные параметры: {'pca__n_components': 26}\n",
      "Точность на тестовой выборке: 0.7762295081967213\n",
      "\n",
      "LogisticRegression\n",
      "Оптимальные параметры: {'pca__n_components': 26}\n",
      "Точность на тестовой выборке: 0.8885245901639345\n",
      "\n",
      "GaussianNB\n",
      "Оптимальные параметры: {'pca__n_components': 5}\n",
      "Точность на тестовой выборке: 0.330327868852459\n",
      "\n",
      "SVC\n",
      "Оптимальные параметры: {'pca__n_components': 26}\n",
      "Точность на тестовой выборке: 0.8729508196721312\n",
      "\n",
      "MLPClassifier\n",
      "Оптимальные параметры: {'pca__n_components': 25}\n",
      "Точность на тестовой выборке: 0.4704918032786885\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Оптимальные параметры: {'pca__n_components': 10}\n",
      "Точность на тестовой выборке: 0.24262295081967214\n",
      "\n",
      "RandomForestClassifier\n",
      "Оптимальные параметры: {'pca__n_components': 26}\n",
      "Точность на тестовой выборке: 0.5229508196721312\n",
      "\n",
      "Исследование подмножества признаков lpc\n",
      "KNeighborsClassifier\n",
      "Оптимальные параметры: {'pca__n_components': 10}\n",
      "Точность на тестовой выборке: 0.21065573770491802\n",
      "\n",
      "LogisticRegression\n",
      "Оптимальные параметры: {'pca__n_components': 10}\n",
      "Точность на тестовой выборке: 0.22459016393442624\n",
      "\n",
      "GaussianNB\n",
      "Оптимальные параметры: {'pca__n_components': 10}\n",
      "Точность на тестовой выборке: 0.2540983606557377\n",
      "\n",
      "SVC\n",
      "Оптимальные параметры: {'pca__n_components': 10}\n",
      "Точность на тестовой выборке: 0.24672131147540985\n",
      "\n",
      "MLPClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stas\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\stas\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\stas\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимальные параметры: {'pca__n_components': 10}\n",
      "Точность на тестовой выборке: 0.3163934426229508\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Оптимальные параметры: {'pca__n_components': 10}\n",
      "Точность на тестовой выборке: 0.16065573770491803\n",
      "\n",
      "RandomForestClassifier\n",
      "Оптимальные параметры: {'pca__n_components': 10}\n",
      "Точность на тестовой выборке: 0.2860655737704918\n",
      "\n",
      "Исследование подмножества признаков formants\n",
      "KNeighborsClassifier\n",
      "Оптимальные параметры: {'pca__n_components': 13}\n",
      "Точность на тестовой выборке: 0.04836065573770492\n",
      "\n",
      "LogisticRegression\n",
      "Оптимальные параметры: {'pca__n_components': 10}\n",
      "Точность на тестовой выборке: 0.029508196721311476\n",
      "\n",
      "GaussianNB\n",
      "Оптимальные параметры: {'pca__n_components': 10}\n",
      "Точность на тестовой выборке: 0.054098360655737705\n",
      "\n",
      "SVC\n",
      "Оптимальные параметры: {'pca__n_components': 10}\n",
      "Точность на тестовой выборке: 0.03524590163934426\n",
      "\n",
      "MLPClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stas\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\stas\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\stas\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\stas\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\stas\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\stas\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\stas\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимальные параметры: {'pca__n_components': 13}\n",
      "Точность на тестовой выборке: 0.06393442622950819\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Оптимальные параметры: {'pca__n_components': 13}\n",
      "Точность на тестовой выборке: 0.031967213114754096\n",
      "\n",
      "RandomForestClassifier\n",
      "Оптимальные параметры: {'pca__n_components': 13}\n",
      "Точность на тестовой выборке: 0.0680327868852459\n",
      "\n",
      "Исследование подмножества признаков whole\n",
      "KNeighborsClassifier\n",
      "Оптимальные параметры: {'pca__n_components': 45}\n",
      "Точность на тестовой выборке: 0.7557377049180328\n",
      "\n",
      "LogisticRegression\n",
      "Оптимальные параметры: {'pca__n_components': 49}\n",
      "Точность на тестовой выборке: 0.8901639344262295\n",
      "\n",
      "GaussianNB\n",
      "Оптимальные параметры: {'pca__n_components': 5}\n",
      "Точность на тестовой выборке: 0.2934426229508197\n",
      "\n",
      "SVC\n",
      "Оптимальные параметры: {'pca__n_components': 40}\n",
      "Точность на тестовой выборке: 0.8491803278688524\n",
      "\n",
      "MLPClassifier\n",
      "Оптимальные параметры: {'pca__n_components': 45}\n",
      "Точность на тестовой выборке: 0.4598360655737705\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Оптимальные параметры: {'pca__n_components': 49}\n",
      "Точность на тестовой выборке: 0.22540983606557377\n",
      "\n",
      "RandomForestClassifier\n",
      "Оптимальные параметры: {'pca__n_components': 35}\n",
      "Точность на тестовой выборке: 0.48278688524590163\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, feat_slice in slices.items():\n",
    "    \n",
    "    print('Исследование подмножества признаков', name)\n",
    "    \n",
    "    feature_count = X_train[:, feat_slice].shape[1]\n",
    "    n_components = np.unique(list(np.arange(5, feature_count + 1, 5, dtype=int)) + [feature_count])\n",
    "    \n",
    "    for model in models:\n",
    "        \n",
    "        print(model.__class__.__name__)\n",
    "        \n",
    "        pca = PCA()\n",
    "        pipe = Pipeline(steps=[('pca', pca), ('model', model)])\n",
    "        estimator = GridSearchCV(pipe, dict(pca__n_components=n_components), cv=3)\n",
    "        estimator.fit(X_train[:, feat_slice], y_train)\n",
    "\n",
    "        print('Оптимальные параметры:', estimator.best_params_)\n",
    "        print('Точность на тестовой выборке:', estimator.best_estimator_.score(X_test[:, feat_slice], y_test))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Выводы__\n",
    "1. Самые сильные признаки - MFCC. Только на них получается точность, как на всей совокупности признаков. Лидеры - логистическая регрессия и SVM. Точность порядка 88%. Недостаок SVM - очень долгое обучение. kNN показало тоже неплохой результат, и можно попытаться оптимизировать.\n",
    "2. Признаки LPC одинаково плохо сработали. Все методы показали низкую точность классификации.\n",
    "3. Признаки на основе формант показали чрезвычайно низкую точность классификации. Они не подходят для решения задачи голосовой идентификации. По крайней мере сами по себе.\n",
    "4. Совокупность всех признаков позволяет чуть улучшить результат классификации. Лидер снова логистическая регрессия (89%). kNN и SVM тоже кандидаты на дальнейшую оптимизацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
